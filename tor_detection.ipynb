{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tor_detection.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K393OUN2VdZ8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf_PwqyFVdZ8"
      },
      "source": [
        "datapath = '/content/drive/MyDrive/SelectedFeatures-10s-TOR-NonTOR.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA68okdGVdZ8"
      },
      "source": [
        "# Read data from csv\n",
        "dataframe = pd.read_csv(datapath,low_memory=False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBqXwjReVdZ8"
      },
      "source": [
        "# Normalise the data\n",
        "def dfNormalize(df):\n",
        "    for feature_name in df.columns:\n",
        "        df.loc[:,feature_name]= pd.to_numeric(df.loc[:,feature_name], errors='coerce').fillna(0)\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()   \n",
        "        if (max_value - min_value) > 0:\n",
        "            df.loc[:,feature_name] = (df.loc[:,feature_name] - min_value) / (max_value - min_value)\n",
        "        else:\n",
        "            df.loc[:,feature_name] = (df.loc[:,feature_name]- min_value)    \n",
        "    return df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48J5mSEBVdZ8"
      },
      "source": [
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slhc8SgjVdZ8",
        "outputId": "411bbb5e-0eb7-40c9-bb02-ca9235378bda"
      },
      "source": [
        "# Randomly permute the data\n",
        "print(dataframe.shape)\n",
        "dataframe = dataframe.reindex(np.random.permutation(dataframe.index)).copy()\n",
        "print(dataframe.describe())\n",
        "print (list(dataframe))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(67834, 29)\n",
            "        Source Port   Destination Port  ...      Idle Max      Idle Min\n",
            "count  67834.000000       67834.000000  ...  6.783400e+04  6.783400e+04\n",
            "mean   37912.753324       11566.395967  ...  3.085054e+05  3.085054e+05\n",
            "std    20986.077326       18374.765123  ...  1.453953e+06  1.453953e+06\n",
            "min       21.000000          21.000000  ...  0.000000e+00  0.000000e+00\n",
            "25%    19305.000000         137.000000  ...  0.000000e+00  0.000000e+00\n",
            "50%    43677.000000         443.000000  ...  0.000000e+00  0.000000e+00\n",
            "75%    54685.000000       16311.000000  ...  0.000000e+00  0.000000e+00\n",
            "max    65534.000000       65514.000000  ...  9.998126e+06  9.998126e+06\n",
            "\n",
            "[8 rows x 26 columns]\n",
            "['Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Protocol', ' Flow Duration', ' Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Active Mean', ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', 'label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PAPS8UwVdZ8",
        "outputId": "c131e6df-94ac-4bf9-f302-c380c554a525"
      },
      "source": [
        "keys = dataframe.keys()\n",
        "feature_keys = keys[1:2] # adding source port\n",
        "feature_keys = feature_keys.append(keys[3:4]) # adding destination port\n",
        "feature_keys = feature_keys.append(keys[5:len(keys)-1]) # adding rest of features without label field 25 features\n",
        "new_feature_keys = [' Source Port', ' Destination Port', ' Flow Duration',' Flow IAT Std',' Flow IAT Min', 'Fwd IAT Mean', ' Fwd IAT Std', 'Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max',' Bwd IAT Min']\n",
        "data_to_process = dataframe[feature_keys].copy()\n",
        "#data_to_process = dataframe[new_feature_keys].copy()\n",
        "x_normalised = dfNormalize(data_to_process)\n",
        "x_normalised = clean_dataset(x_normalised).copy()\n",
        "print(x_normalised.describe())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Source Port   Destination Port  ...      Idle Max      Idle Min\n",
            "count  67828.000000       67828.000000  ...  67828.000000  67828.000000\n",
            "mean       0.578420           0.176270  ...      0.030859      0.030859\n",
            "std        0.320324           0.280536  ...      0.145429      0.145429\n",
            "min        0.000000           0.000000  ...      0.000000      0.000000\n",
            "25%        0.294354           0.001771  ...      0.000000      0.000000\n",
            "50%        0.666410           0.006443  ...      0.000000      0.000000\n",
            "75%        0.834399           0.248729  ...      0.000000      0.000000\n",
            "max        1.000000           1.000000  ...      1.000000      1.000000\n",
            "\n",
            "[8 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "755DbLtCVdZ8"
      },
      "source": [
        "# get the train and test data\n",
        "x_train = x_normalised.sample(frac=0.8, replace=True)\n",
        "x_test = x_normalised.drop(x_train.index)\n",
        "\n",
        "# change the labels and affix them\n",
        "change_labels = lambda x: 1 if x == 'nonTOR' else 0\n",
        "y_train = dataframe['label'].apply(change_labels).loc[x_train.index]\n",
        "y_test = dataframe['label'].apply(change_labels).loc[x_test.index]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ-csKSDVdZ8",
        "outputId": "e88d85da-5809-4ce6-fab7-edf0b10ef4c5"
      },
      "source": [
        "# Figure the Feature dimensions so that it can be used in Deep Neural Net later\n",
        "feature_dim = x_train.shape[1]\n",
        "print (feature_dim)\n",
        "print (x_train[y_train==0].shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "(6368, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6VYUe-_VdZ8",
        "outputId": "a1d648b0-3435-4760-dfe2-ec468767c1c9"
      },
      "source": [
        "# Logistic Regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "lr=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "lr.fit(x_train, y_train)\n",
        "y_predict = lr.predict(x_test)\n",
        "target_names = ['class 0 - NonTor', 'class 1 - Tor']\n",
        "print(classification_report(y_test, y_predict, target_names=target_names))\n",
        "print(\"Accuracy = {:.2f}\".format(lr.score(x_test, y_test.values)*100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "class 0 - NonTor       0.80      0.55      0.65      3643\n",
            "   class 1 - Tor       0.94      0.98      0.96     26746\n",
            "\n",
            "        accuracy                           0.93     30389\n",
            "       macro avg       0.87      0.77      0.81     30389\n",
            "    weighted avg       0.92      0.93      0.92     30389\n",
            "\n",
            "Accuracy = 92.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JxM27Abta11s",
        "outputId": "845da9e2-84d5-45f6-8a3e-cccd5a2f47b5"
      },
      "source": [
        "new_feature_keys[np.argsort(lr.coef_[0])[::-1][0]] # which feature has highest impact"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Fwd IAT Mean'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2xPbkoeVdZ8",
        "outputId": "e2a2ce4f-efda-41f4-96b6-b2fd15a44193"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "hidden_layers = 10\n",
        "neurons_num = 200\n",
        "model = Sequential()\n",
        "model.add(Dense(feature_dim, input_dim= feature_dim, kernel_initializer='normal', activation='relu'))\n",
        "for _ in range(0, hidden_layers-1):\n",
        "    model.add(Dense(neurons_num, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1,kernel_initializer='normal', activation='sigmoid'))\n",
        "print (model.summary())\n",
        "model.compile(optimizer=\"adam\",loss='binary_crossentropy', metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 25)                650       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 200)               5200      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 327,651\n",
            "Trainable params: 327,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he6sEjAIVdZ8",
        "outputId": "04ee7f6c-28a8-4cf4-c87b-0588afdc90f8"
      },
      "source": [
        "# Deep Neural Net Implementation using Keras and TensorFlow\n",
        "# Compute the accuracies and visualise using TensorBoard\n",
        "from time import time\n",
        "model.fit(x_train,y_train, epochs=20, batch_size=100, verbose=2,validation_split=0.1)\n",
        "scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "#loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"\\nTest %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "scores_0 = model.evaluate(x_test[y_test==0], y_test[y_test==0])\n",
        "print(\"\\nTest %s for class 0: %.2f%%\" % (model.metrics_names[1], scores_0[1]*100))\n",
        "scores_1 = model.evaluate(x_test[y_test==1], y_test[y_test==1])\n",
        "print(\"\\nTest %s for class 1: %.2f%%\" % (model.metrics_names[1], scores_1[1]*100))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "489/489 - 5s - loss: 0.1952 - accuracy: 0.9278 - val_loss: 0.1259 - val_accuracy: 0.9490 - 5s/epoch - 10ms/step\n",
            "Epoch 2/20\n",
            "489/489 - 4s - loss: 0.1374 - accuracy: 0.9445 - val_loss: 0.1307 - val_accuracy: 0.9504 - 4s/epoch - 8ms/step\n",
            "Epoch 3/20\n",
            "489/489 - 4s - loss: 0.1333 - accuracy: 0.9450 - val_loss: 0.1201 - val_accuracy: 0.9491 - 4s/epoch - 8ms/step\n",
            "Epoch 4/20\n",
            "489/489 - 4s - loss: 0.1273 - accuracy: 0.9456 - val_loss: 0.1182 - val_accuracy: 0.9530 - 4s/epoch - 8ms/step\n",
            "Epoch 5/20\n",
            "489/489 - 4s - loss: 0.1259 - accuracy: 0.9468 - val_loss: 0.1200 - val_accuracy: 0.9440 - 4s/epoch - 8ms/step\n",
            "Epoch 6/20\n",
            "489/489 - 4s - loss: 0.1223 - accuracy: 0.9476 - val_loss: 0.1204 - val_accuracy: 0.9508 - 4s/epoch - 9ms/step\n",
            "Epoch 7/20\n",
            "489/489 - 4s - loss: 0.1209 - accuracy: 0.9485 - val_loss: 0.1129 - val_accuracy: 0.9512 - 4s/epoch - 8ms/step\n",
            "Epoch 8/20\n",
            "489/489 - 4s - loss: 0.1183 - accuracy: 0.9506 - val_loss: 0.1165 - val_accuracy: 0.9445 - 4s/epoch - 8ms/step\n",
            "Epoch 9/20\n",
            "489/489 - 4s - loss: 0.1147 - accuracy: 0.9506 - val_loss: 0.1071 - val_accuracy: 0.9552 - 4s/epoch - 8ms/step\n",
            "Epoch 10/20\n",
            "489/489 - 4s - loss: 0.1126 - accuracy: 0.9524 - val_loss: 0.1129 - val_accuracy: 0.9563 - 4s/epoch - 8ms/step\n",
            "Epoch 11/20\n",
            "489/489 - 4s - loss: 0.1102 - accuracy: 0.9534 - val_loss: 0.1094 - val_accuracy: 0.9534 - 4s/epoch - 8ms/step\n",
            "Epoch 12/20\n",
            "489/489 - 4s - loss: 0.1093 - accuracy: 0.9545 - val_loss: 0.1167 - val_accuracy: 0.9517 - 4s/epoch - 8ms/step\n",
            "Epoch 13/20\n",
            "489/489 - 4s - loss: 0.1109 - accuracy: 0.9517 - val_loss: 0.1049 - val_accuracy: 0.9589 - 4s/epoch - 8ms/step\n",
            "Epoch 14/20\n",
            "489/489 - 4s - loss: 0.1058 - accuracy: 0.9562 - val_loss: 0.1073 - val_accuracy: 0.9578 - 4s/epoch - 8ms/step\n",
            "Epoch 15/20\n",
            "489/489 - 4s - loss: 0.1046 - accuracy: 0.9563 - val_loss: 0.0973 - val_accuracy: 0.9609 - 4s/epoch - 8ms/step\n",
            "Epoch 16/20\n",
            "489/489 - 4s - loss: 0.1025 - accuracy: 0.9576 - val_loss: 0.0966 - val_accuracy: 0.9626 - 4s/epoch - 8ms/step\n",
            "Epoch 17/20\n",
            "489/489 - 4s - loss: 0.0986 - accuracy: 0.9601 - val_loss: 0.1013 - val_accuracy: 0.9565 - 4s/epoch - 8ms/step\n",
            "Epoch 18/20\n",
            "489/489 - 4s - loss: 0.0979 - accuracy: 0.9607 - val_loss: 0.1024 - val_accuracy: 0.9536 - 4s/epoch - 9ms/step\n",
            "Epoch 19/20\n",
            "489/489 - 4s - loss: 0.0972 - accuracy: 0.9615 - val_loss: 0.0934 - val_accuracy: 0.9622 - 4s/epoch - 8ms/step\n",
            "Epoch 20/20\n",
            "489/489 - 4s - loss: 0.0956 - accuracy: 0.9623 - val_loss: 0.1025 - val_accuracy: 0.9587 - 4s/epoch - 8ms/step\n",
            "950/950 - 1s - loss: 0.1036 - accuracy: 0.9588 - 1s/epoch - 1ms/step\n",
            "\n",
            "Test accuracy: 95.88%\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8051\n",
            "\n",
            "Test accuracy for class 0: 80.51%\n",
            "836/836 [==============================] - 2s 2ms/step - loss: 0.0598 - accuracy: 0.9797\n",
            "\n",
            "Test accuracy for class 1: 97.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4R97g7zVdZ8"
      },
      "source": [
        "nn_y_predict = (model.predict(x_test)>0.5).astype(int)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x6h-JXOVdZ8",
        "outputId": "9451db85-dd64-430f-ae7c-2eea6842c45a"
      },
      "source": [
        "print(classification_report(y_test, nn_y_predict, target_names=target_names))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "class 0 - NonTor       0.82      0.75      0.78      3627\n",
            "   class 1 - Tor       0.97      0.98      0.97     26878\n",
            "\n",
            "        accuracy                           0.95     30505\n",
            "       macro avg       0.89      0.86      0.88     30505\n",
            "    weighted avg       0.95      0.95      0.95     30505\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l9LmPpwYiO0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}